{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/born-2-code/.local/lib/python2.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.24) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 15\n",
    "MAX_VOCAB_SIZE = 50000\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "\n",
    "word2vec = {}\n",
    "with open('glove.6B.50d.txt') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def normalize_text(text):\n",
    "    norm_text = text.lower()\n",
    "    # Replace breaks with spaces\n",
    "    norm_text = norm_text.replace('<br />', ' ')\n",
    "    # Pad punctuation with spaces on both sides\n",
    "    norm_text = re.sub(r\"([\\.\\\",\\(\\)!\\?;:])\", \" \\\\1 \", norm_text)\n",
    "    return norm_text\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    return \" \".join([item.lower() for item in text.split() if item not in stop])\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    return ''.join([\"\" if ord(i) < 32 or ord(i) > 126 else i for i in text])\n",
    "\n",
    "def process_train_data(df, filename):\n",
    "    \n",
    "    df = df[df.gold_label != \"-\"]\n",
    "    df['gold_label'] = df['gold_label'].map({val: i for i, val in enumerate(df['gold_label'].unique())})\n",
    "    df['sentence1'] = df['sentence1'].apply(remove_non_ascii)\n",
    "    df['sentence1'] = df['sentence1'].apply(normalize_text)\n",
    "    df['sentence1'] = df['sentence1'].apply(remove_stop_words)\n",
    "    df['sentence1'] = df['sentence1'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "    df['sentence2'] = df['sentence2'].apply(remove_non_ascii)\n",
    "    df['sentence2'] = df['sentence2'].apply(normalize_text)\n",
    "    df['sentence2'] = df['sentence2'].apply(remove_stop_words)\n",
    "    df['sentence2'] = df['sentence2'].str.replace('[^\\w\\s]','')\n",
    "    texts = df['sentence1'].values + df['sentence2'].values\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "    \n",
    "    tokenizer.fit_on_texts(texts)\n",
    "\n",
    "    word2idx = tokenizer.word_index\n",
    "    \n",
    "    sentence1 = tokenizer.texts_to_sequences(df['sentence1'])\n",
    "    sentence2 = tokenizer.texts_to_sequences(df['sentence2'])\n",
    "    \n",
    "    sentence1 = pad_sequences(sentence1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    sentence2 = pad_sequences(sentence2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    \n",
    "    num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
    "    embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "    for word, i in word2idx.items():\n",
    "          if i < MAX_VOCAB_SIZE:\n",
    "            embedding_vector = word2vec.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    sentence1_embeddings = []\n",
    "    for sentence in sentence1:\n",
    "        temp = []\n",
    "        for val in sentence:\n",
    "            temp.append(embedding_matrix[val])\n",
    "        sentence1_embeddings.append(np.asarray(temp))\n",
    "    sentence1_embeddings = np.asarray(sentence1_embeddings)\n",
    "    \n",
    "    sentence2_embeddings = []\n",
    "    for sentence in sentence2:\n",
    "        temp = []\n",
    "        for val in sentence:\n",
    "            temp.append(embedding_matrix[val])\n",
    "        sentence2_embeddings.append(np.asarray(temp))\n",
    "    sentence2_embeddings = np.asarray(sentence2_embeddings)\n",
    "    \n",
    "    with open('sentence1_embedd_%s'%filename,'w') as outfile:\n",
    "        np.save(outfile, sentence1_embeddings.reshape(sentence1_embeddings.shape[0],-1))\n",
    "        \n",
    "    with open('sentence2_embedd_%s'%filename,'w') as outfile:\n",
    "        np.save(outfile, sentence2_embeddings.reshape(sentence1_embeddings.shape[0],-1))\n",
    "        \n",
    "    labels = np.asarray(df['gold_label'])\n",
    "    labels.astype(np.float32)\n",
    "    \n",
    "    true_label = np.zeros((labels.shape[0], 3))\n",
    "    true_label[np.arange(labels.shape[0]), labels] = 1\n",
    "\n",
    "    with open('label_%s'%filename, 'w') as outfile:\n",
    "        np.save(outfile, true_label)\n",
    "        \n",
    "    return tokenizer, embedding_matrix\n",
    "        \n",
    "        \n",
    "def process_test_data(df, filename, tokenizer, embedding_matrix):\n",
    "    \n",
    "    df = df[df.gold_label != \"-\"]\n",
    "    df['gold_label'] = df['gold_label'].map({val: i for i, val in enumerate(df['gold_label'].unique())})\n",
    "    df['sentence1'] = df['sentence1'].apply(remove_non_ascii)\n",
    "    df['sentence1'] = df['sentence1'].apply(normalize_text)\n",
    "    df['sentence1'] = df['sentence1'].apply(remove_stop_words)\n",
    "    df['sentence1'] = df['sentence1'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "    df['sentence2'] = df['sentence2'].apply(remove_non_ascii)\n",
    "    df['sentence2'] = df['sentence2'].apply(normalize_text)\n",
    "    df['sentence2'] = df['sentence2'].apply(remove_stop_words)\n",
    "    df['sentence2'] = df['sentence2'].str.replace('[^\\w\\s]','')\n",
    "    \n",
    "    ## tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "    # texts = df['sentence1'].values + df['sentence2'].values\n",
    "    # tokenizer.fit_on_texts(texts)\n",
    "\n",
    "    # word2idx = tokenizer.word_index\n",
    "    \n",
    "    sentence1 = tokenizer.texts_to_sequences(df['sentence1'])\n",
    "    sentence2 = tokenizer.texts_to_sequences(df['sentence2'])\n",
    "    \n",
    "    sentence1 = pad_sequences(sentence1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    sentence2 = pad_sequences(sentence2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    \n",
    "    \"\"\"\n",
    "    num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
    "    embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "    for word, i in word2idx.items():\n",
    "          if i < MAX_VOCAB_SIZE:\n",
    "            embedding_vector = word2vec.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence1_embeddings = []\n",
    "    for sentence in sentence1:\n",
    "        temp = []\n",
    "        for val in sentence:\n",
    "            temp.append(embedding_matrix[val])\n",
    "        sentence1_embeddings.append(np.asarray(temp))\n",
    "    sentence1_embeddings = np.asarray(sentence1_embeddings)\n",
    "    \n",
    "    sentence2_embeddings = []\n",
    "    for sentence in sentence2:\n",
    "        temp = []\n",
    "        for val in sentence:\n",
    "            temp.append(embedding_matrix[val])\n",
    "        sentence2_embeddings.append(np.asarray(temp))\n",
    "    sentence2_embeddings = np.asarray(sentence2_embeddings)\n",
    "    \n",
    "    with open('sentence1_embedd_%s'%filename,'w') as outfile:\n",
    "        np.save(outfile, sentence1_embeddings.reshape(sentence1_embeddings.shape[0],-1))\n",
    "        \n",
    "    with open('sentence2_embedd_%s'%filename,'w') as outfile:\n",
    "        np.save(outfile, sentence2_embeddings.reshape(sentence1_embeddings.shape[0],-1))\n",
    "        \n",
    "    labels = np.asarray(df['gold_label'])\n",
    "    labels.astype(np.float32)\n",
    "    \n",
    "    true_label = np.zeros((labels.shape[0], 3))\n",
    "    true_label[np.arange(labels.shape[0]), labels] = 1\n",
    "    print(true_label.shape)\n",
    "    with open('label_%s'%filename, 'w') as outfile:\n",
    "       np.save(outfile, true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'train'\n",
    "with open(filename) as f:\n",
    "    data = pd.DataFrame(json.loads(line) for line in f)\n",
    "    df = data[['gold_label', 'sentence1', 'sentence2']]\n",
    "tokenizer, embedding_matrix = process_train_data(df, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/born-2-code/.local/lib/python2.7/site-packages/ipykernel_launcher.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/born-2-code/.local/lib/python2.7/site-packages/ipykernel_launcher.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/born-2-code/.local/lib/python2.7/site-packages/ipykernel_launcher.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/born-2-code/.local/lib/python2.7/site-packages/ipykernel_launcher.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/born-2-code/.local/lib/python2.7/site-packages/ipykernel_launcher.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/born-2-code/.local/lib/python2.7/site-packages/ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/born-2-code/.local/lib/python2.7/site-packages/ipykernel_launcher.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/born-2-code/.local/lib/python2.7/site-packages/ipykernel_launcher.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/born-2-code/.local/lib/python2.7/site-packages/ipykernel_launcher.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "filename = 'test'\n",
    "with open(filename) as f:\n",
    "    data = pd.DataFrame(json.loads(line) for line in f)\n",
    "    df = data[['gold_label', 'sentence1', 'sentence2']]\n",
    "process_test_data(df, filename, tokenizer, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'neutral', u'entailment', u'contradiction', u'-'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gold_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'-': 3, u'contradiction': 2, u'entailment': 1, u'neutral': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{val: i for i, val in enumerate(df['gold_label'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
